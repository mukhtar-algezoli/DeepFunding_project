{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 442368 || all params: 33802368 || trainable%: 1.3086893793949583\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b56336d8f845e0a9613876048ea324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating triplets:   0%|          | 0/14 [00:00<?, ?group/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from triplet_dataset import get_dataset, get_sentence_id_label_df, TripletDataset\n",
    "from network import get_sts_model\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from model_evaluation import  compare_sactter_plots\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from peft import LoraConfig\n",
    "\n",
    "RANK = 16\n",
    "PEFT_CONFIG = LoraConfig(inference_mode=False, \n",
    "              r=RANK, \n",
    "              lora_alpha=RANK*2, \n",
    "              lora_dropout=0.05,\n",
    "              target_modules=['value','query','key']\n",
    "              )\n",
    "global DEVICE\n",
    "global MODEL_PATH\n",
    "global MODEL\n",
    "global TOKENIZER\n",
    "global DATA\n",
    "global VIS_DATA\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "MODEL_PATH = 'sentence-transformers/all-MiniLM-L12-v1'\n",
    "MODEL = get_sts_model(model_path=MODEL_PATH, device=DEVICE, pef_config=PEFT_CONFIG)\n",
    "TOKENIZER = MODEL.tokenizer\n",
    "DATA = get_dataset()\n",
    "VIS_DATA = get_sentence_id_label_df()\n",
    "\n",
    "\n",
    "def gen_vis_embeddings(no_peft=False):\n",
    "    embeddings = []\n",
    "    sentences = VIS_DATA['sentence'].tolist()\n",
    "    for sentence in tqdm(sentences, unit='sentence', desc='Generating embeddings'):\n",
    "        if no_peft:\n",
    "            print('Do Something')\n",
    "        else:\n",
    "            embedding = MODEL(sentence).detach().cpu().numpy()\n",
    "        embeddings.append(embedding)\n",
    "    embeddings = np.array(embeddings).squeeze()\n",
    "    embeddings = TSNE(n_components=2).fit_transform(embeddings)\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Model without\n",
    "    # bare_embeddings = gen_vis_embeddings(no_peft=True)\n",
    "    # ids = VIS_DATA['id'].tolist()\n",
    "    # print('Bare model Clustering: ')\n",
    "    # compare_sactter_plots(bare_embeddings, None, ids)\n",
    "    # print('='*100)\n",
    "    batch_size = 8\n",
    "    optimizer = torch.optim.AdamW(params=MODEL.parameters(), lr=1e-5)\n",
    "    triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "    num_epochs = 5\n",
    "    eval_every = 100\n",
    "    save_model_every = 1000\n",
    "    print('Training model...')\n",
    "    train(batch_size, optimizer, triplet_loss, num_epochs, eval_every, save_model_every)\n",
    "    \n",
    "\n",
    "def train(batch_size,optimizer, triplet_loss, num_epochs, eval_every, save_model_every):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_dataset = TripletDataset(DATA, tokenizer=TOKENIZER, device=DEVICE, batch_size=batch_size, shuffle=True, max_len=200)\n",
    "        loss = 0\n",
    "        steps = 0\n",
    "        accumelated_loss = 0\n",
    "        tbar = tqdm(train_dataset, unit='batch')\n",
    "        for input in tbar:\n",
    "                steps += 1\n",
    "                anchor = MODEL(input[0])\n",
    "                positive = MODEL(input[1])\n",
    "                negative = MODEL(input[2])\n",
    "                loss = triplet_loss(anchor, positive, negative)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                accumelated_loss += loss.item()\n",
    "                tbar.set_description(f'Epoch {epoch} current loss: {loss:.2f} avaerage loss: {accumelated_loss/steps:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "                if steps % eval_every == 0:\n",
    "                    print('Evaluating model')\n",
    "                    print(f'Avaerage loss: {accumelated_loss/steps:.2f} ')\n",
    "                    # embeddings = gen_vis_embeddings()\n",
    "                    # ids = VIS_DATA['id'].tolist()\n",
    "                    # print('Model Clustering: ')\n",
    "                    # compare_sactter_plots(embeddings,None, ids)\n",
    "                    # print('='*100)\n",
    "                if steps % 200 == 0:\n",
    "                    accumelated_loss = 0\n",
    "\n",
    "                if steps % save_model_every == 0:\n",
    "                    print('Saving model')\n",
    "                    if not os.path.exists('./models'):\n",
    "                        os.makedirs('./models')\n",
    "                    \n",
    "                    lora_model = MODEL.Bert_representations\n",
    "\n",
    "                    if not os.path.exists('./models/LoRa'):\n",
    "                        os.makedirs('./models/LoRa')\n",
    "\n",
    "                    #model name without / character\n",
    "                    short_model_name = MODEL_PATH.split('/')[-1]\n",
    "                    lora_save_path = f'./models/LoRa/lora_model_{short_model_name}_{steps}'\n",
    "                    lora_model.save_pretrained(lora_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109ddbaf18574b9b9c6a2fe0a0199143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batching data:   0%|          | 0/7112 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b27f7b333f46f499f3e24a12447592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing data:   0%|          | 0/890 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4fd06364f54995a62e9cfe5f347c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/890 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "Avaerage loss: 0.64 \n",
      "Evaluating model\n",
      "Avaerage loss: 0.00 \n",
      "Evaluating model\n",
      "Avaerage loss: 0.18 \n",
      "Evaluating model\n",
      "Avaerage loss: 0.00 \n"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
