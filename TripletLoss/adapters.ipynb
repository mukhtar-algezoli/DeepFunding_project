{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from peft import get_peft_model, PeftConfig, PeftModel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lora_peft_path= 'ammarnasr/LoRa_all-MiniLM-L12-v1'\n",
    "base_model_path = 'sentence-transformers/all-MiniLM-L12-v1'\n",
    "device='cuda'\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "base_model = AutoModel.from_pretrained(base_model_path)\n",
    "final_model = PeftModel.from_pretrained(base_model, lora_peft_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_evaluation import  calculate_accuracy_from_embeddings\n",
    "from triplet_dataset import get_sentence_id_label_df\n",
    "\n",
    "data_path = './dataset/data.csv'\n",
    "\n",
    "\n",
    "\n",
    "eval_data_df = get_sentence_id_label_df(data_path)\n",
    "sentences = eval_data_df['sentence']\n",
    "labels = eval_data_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "embeddings = []\n",
    "for sentence in tqdm(sentences, unit='sentence', desc='Generating embeddings'):\n",
    "    embedding = model(sentence).detach().cpu().numpy()\n",
    "    embeddings.append(embedding)\n",
    "embeddings = np.array(embeddings).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "rank = 64\n",
    "peft_config = LoraConfig(inference_mode=False,\n",
    "            r=rank,\n",
    "            lora_alpha=rank*2,\n",
    "            lora_dropout=0.05,\n",
    "            target_modules=['value','query','key', 'dense']\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "# def calculate_accuracy_from_embeddings(embeddings, labels):\n",
    "#     total = 0\n",
    "#     correct = 0\n",
    "#     print('Calculating accuracy...')\n",
    "#     unique_groups = labels.unique()\n",
    "#     print(f'Number of unique groups: {len(unique_groups)}, {unique_groups}')\n",
    "#     avarage_group_embeddings = []\n",
    "#     for group in unique_groups:\n",
    "#         group_indices = labels[labels == group].index\n",
    "#         group_embeddings = embeddings[group_indices]\n",
    "#         avarage_group_embeddings.append(group_embeddings.mean(axis=0))\n",
    "#     avarage_group_embeddings = np.array(avarage_group_embeddings)\n",
    "#     print(f'Avarage group embeddings shape: {avarage_group_embeddings.shape}')\n",
    "#     for i, embedding in enumerate(embeddings):\n",
    "#         total += 1\n",
    "#         distances = cosine_distances([embedding], avarage_group_embeddings)\n",
    "#         print(f'Distances shape: {distances.shape}, distances: {distances}, min: {np.argmin(distances)}, label: {labels[i]}')\n",
    "#         break\n",
    "    #     if np.argmin(distances) == labels[i]:\n",
    "    #         correct += 1\n",
    "    #     acc_tbar.set_postfix({'Accuracy': correct / total})\n",
    "\n",
    "    \n",
    "    # acc  = correct / total\n",
    "    # print(f'Accuracy: {acc}')\n",
    "    # return acc\n",
    "accuracy = calculate_accuracy_from_embeddings(embeddings, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# work_dir = '/content/drive/MyDrive/DeepFund/'\n",
    "# os.chdir(work_dir)\n",
    "# os.chdir('DeepFunding_project/TripletLoss')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from triplet_dataset import get_dataset, get_sentence_id_label_df, TripletDataset\n",
    "from network import get_sts_model\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from model_evaluation import  compare_sactter_plots\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from peft import LoraConfig\n",
    "\n",
    "\n",
    "def calculate_dsiatances_from_embeddings(embeddings, labels):\n",
    "    # Calculate average distances within and across groups\n",
    "    group_distances = []\n",
    "    total_distances = []\n",
    "    all_res = {\n",
    "        'group_id': [],\n",
    "        'group_distance': [],\n",
    "        'total_distance': [],\n",
    "    }\n",
    "    unique_groups = labels.unique()\n",
    "\n",
    "    for group in unique_groups:\n",
    "        group_indices = labels[labels == group].index\n",
    "        group_embeddings = embeddings[group_indices]\n",
    "        \n",
    "        # Calculate pairwise cosine distances within the group\n",
    "        group_distance = cosine_distances(group_embeddings).mean()\n",
    "        group_distances.append(group_distance)\n",
    "        \n",
    "        # Calculate pairwise cosine distances across groups\n",
    "        other_indices = labels[labels != group].index\n",
    "        other_embeddings = embeddings[other_indices]\n",
    "        total_distance = cosine_distances(group_embeddings, other_embeddings).mean()\n",
    "        total_distances.append(total_distance)\n",
    "\n",
    "        all_res['group_id'].append(group)\n",
    "        all_res['group_distance'].append(group_distance)\n",
    "        all_res['total_distance'].append(total_distance)\n",
    "\n",
    "    # Calculate the average distances\n",
    "    average_group_distance = sum(group_distances) / len(group_distances)\n",
    "    average_total_distance = sum(total_distances) / len(total_distances)\n",
    "\n",
    "    print(\"Average distance within groups:\", average_group_distance)\n",
    "    print(\"Average distance across groups:\", average_total_distance)\n",
    "\n",
    "    return average_group_distance, average_total_distance, all_res\n",
    "\n",
    "\n",
    "def gen_vis_embeddings(no_peft=False, tsne=True):\n",
    "    embeddings = []\n",
    "    sentences = VIS_DATA['sentence'].tolist()\n",
    "    for sentence in tqdm(sentences, unit='sentence', desc='Generating embeddings'):\n",
    "        if no_peft:\n",
    "            print('Do Something')\n",
    "        else:\n",
    "            embedding = MODEL(sentence).detach().cpu().numpy()\n",
    "        embeddings.append(embedding)\n",
    "    embeddings = np.array(embeddings).squeeze()\n",
    "    if tsne:\n",
    "        embeddings = TSNE(n_components=2).fit_transform(embeddings)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def main(batch_size=16):\n",
    "    # Model without\n",
    "    # bare_embeddings = gen_vis_embeddings(no_peft=True)\n",
    "    # ids = VIS_DATA['id'].tolist()\n",
    "    # print('Bare model Clustering: ')\n",
    "    # compare_sactter_plots(bare_embeddings, None, ids)\n",
    "    # print('='*100)\n",
    "    optimizer = torch.optim.AdamW(params=MODEL.parameters(), lr=1e-5)\n",
    "    triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "    num_epochs = 5\n",
    "    eval_every = 100\n",
    "    save_model_every = 1000\n",
    "    print('Training model...')\n",
    "    train(batch_size, optimizer, triplet_loss, num_epochs, eval_every, save_model_every)\n",
    "\n",
    "\n",
    "def train(batch_size,optimizer, triplet_loss, num_epochs, eval_every, save_model_every):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_dataset = TripletDataset(DATA, tokenizer=TOKENIZER, device=DEVICE, batch_size=batch_size, shuffle=True, max_len=100)\n",
    "        loss = 0\n",
    "        steps = 0\n",
    "        accumelated_loss = 0\n",
    "        tbar = tqdm(train_dataset, unit='batch')\n",
    "        for input in tbar:\n",
    "                steps += 1\n",
    "                anchor = MODEL(input[0])\n",
    "                positive = MODEL(input[1])\n",
    "                negative = MODEL(input[2])\n",
    "                loss = triplet_loss(anchor, positive, negative)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                accumelated_loss += loss.item()\n",
    "                tbar.set_description(f'Epoch {epoch} current loss: {loss:.2f} avaerage loss: {accumelated_loss/steps:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "                if steps % eval_every == 0:\n",
    "                    print('Evaluating model')\n",
    "                    print(f'Avaerage loss: {accumelated_loss/steps:.2f} ')\n",
    "                    embeddings = gen_vis_embeddings()\n",
    "                    labels = VIS_DATA['label']\n",
    "                    d = calculate_dsiatances_from_embeddings(embeddings, labels)\n",
    "\n",
    "                    \n",
    "                if steps % 500 == 0:\n",
    "                    accumelated_loss = 0\n",
    "                    embeddings = gen_vis_embeddings()\n",
    "                    ids = VIS_DATA['id'].tolist()\n",
    "                    print('Model Clustering: ')\n",
    "                    compare_sactter_plots(embeddings,None, ids)\n",
    "                    print('='*100)\n",
    "\n",
    "                if steps % save_model_every == 0:\n",
    "                    print('Saving model')\n",
    "                    if not os.path.exists('./models'):\n",
    "                        os.makedirs('./models')\n",
    "\n",
    "                    lora_model = MODEL.Bert_representations\n",
    "\n",
    "                    if not os.path.exists('./models/LoRa'):\n",
    "                        os.makedirs('./models/LoRa')\n",
    "\n",
    "                    #model name without / character\n",
    "                    short_model_name = MODEL_PATH.split('/')[-1]\n",
    "                    lora_save_path = f'./models/LoRa/lora_model_{short_model_name}_{steps}'\n",
    "                    lora_model.save_pretrained(lora_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RANK = 64\n",
    "PEFT_CONFIG = LoraConfig(inference_mode=False,\n",
    "              r=RANK,\n",
    "              lora_alpha=RANK*2,\n",
    "              lora_dropout=0.05,\n",
    "              target_modules=['value','query','key', 'dense']\n",
    "              )\n",
    "global DEVICE\n",
    "global MODEL_PATH\n",
    "global MODEL\n",
    "global TOKENIZER\n",
    "global DATA\n",
    "global VIS_DATA\n",
    "DEVICE = 'cuda'\n",
    "MODEL_PATH = 'sentence-transformers/all-MiniLM-L12-v1'\n",
    "MODEL = get_sts_model(model_path=MODEL_PATH, device=DEVICE, pef_config=PEFT_CONFIG)\n",
    "TOKENIZER = MODEL.tokenizer\n",
    "DATA = get_dataset()\n",
    "VIS_DATA = get_sentence_id_label_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Inference #####################\n",
    "global TRAINED_EMDEDDINGS\n",
    "global TRAINED_LABELS\n",
    "TRAINED_EMDEDDINGS = gen_vis_embeddings(tsne=False)\n",
    "TRAINED_LABELS = VIS_DATA['label']\n",
    "\n",
    "def get_closest_group(sentence):\n",
    "    embedding = MODEL(sentence).detach().cpu().numpy()\n",
    "    groups = TRAINED_LABELS.unique()\n",
    "    min_distance = 1000\n",
    "    min_index = 0\n",
    "    correct_group = None\n",
    "    for i, group in enumerate(groups):\n",
    "        group_indices = TRAINED_LABELS[TRAINED_LABELS == group].index\n",
    "        group_embeddings = TRAINED_EMDEDDINGS[group_indices]\n",
    "        distance = cosine_distances(group_embeddings, embedding).mean()\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            min_index = i\n",
    "            correct_group = group\n",
    "    return correct_group, min_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_sents = VIS_DATA['sentence'].tolist()\n",
    "vis_labels = VIS_DATA['label'].tolist()\n",
    "rand_idx = np.random.randint(0, len(vis_sents))\n",
    "rand_sent = vis_sents[rand_idx]\n",
    "rand_label = vis_labels[rand_idx]\n",
    "print(f'Random sentence: {rand_sent}')\n",
    "print(f'Random label: {rand_label}')\n",
    "print(f'Closest group: {get_closest_group(rand_sent)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from peft import get_peft_model, PeftConfig, PeftModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "model_path = 'ammarnasr/LoRa_all-MiniLM-L12-v1'\n",
    "config = PeftConfig.from_pretrained(model_path)\n",
    "bert = AutoModel.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "bert = PeftModel.from_pretrained(bert, model_path)\n",
    "bert.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert.train(mode=True)\n",
    "bert.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the layers of the model, and their trainable status, and their shape\n",
    "for name, param in bert.named_parameters():\n",
    "    if 'lora' in name:\n",
    "        print(name, param.requires_grad, param.shape)\n",
    "\n",
    "#Change the trainable status of the lora layers\n",
    "for name, param in bert.named_parameters():\n",
    "    if 'lora' in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "tbar = tqdm(range(len(vis_sents)), unit='sentence', desc=f'Evaluating model: {correct}/{total}')\n",
    "for i in tbar :\n",
    "    sent = vis_sents[i]\n",
    "    label = vis_labels[i]\n",
    "    closest_group, distance = get_closest_group(sent)\n",
    "    if closest_group == label:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    tbar.set_description(f'Evaluating model: {correct}/{total}')\n",
    "    \n",
    "\n",
    "\n",
    "print(f'Accuracy: {correct/total}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
