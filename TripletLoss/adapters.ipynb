{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model_evaluation import get_vis_data, compare_sactter_plots\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datapreperation import get_processed_input_examples_full\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import os\n",
    "\n",
    "RANK = 2\n",
    "PEFT_CONFIG = LoraConfig(inference_mode=False, \n",
    "              r=RANK, \n",
    "              lora_alpha=RANK*2, \n",
    "              lora_dropout=0.05,\n",
    "              # target_modules=[\"q_lin\",\"k_lin\"]\n",
    "              target_modules=['value','query']\n",
    "              )\n",
    "\n",
    "\n",
    "class MLPLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Head for getting sentence representations over RoBERTa/BERT's CLS representation.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = self.dense(features)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class STS_model(nn.Module): \n",
    "    def __init__(self, model_path, device='cpu', pef_config=None): \n",
    "      super(STS_model, self).__init__() \n",
    "\n",
    "      # Load model from HuggingFace Hub\n",
    "      config = AutoConfig.from_pretrained(model_path, return_dict=True)\n",
    "      self.device = device\n",
    "      self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "      self.Bert_representations = AutoModel.from_pretrained(model_path)\n",
    "      if pef_config is not None:\n",
    "        self.Bert_representations = get_peft_model(self.Bert_representations, pef_config)\n",
    "      self.Bert_representations.to(device)\n",
    "      self.Bert_representations.print_trainable_parameters()\n",
    "      self.MLP_layer = MLPLayer(config)\n",
    "      self.MLP_layer.to(device)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, model_input): \n",
    "      # Tokenize sentences if input is a string or a list of strings\n",
    "        if isinstance(model_input, str) or (isinstance(model_input, list) and isinstance(model_input[0], str)):\n",
    "            model_input = self.tokenizer(model_input, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "            model_input = model_input.to(self.device)\n",
    "            model_output = self.Bert_representations(**model_input)\n",
    "        else:\n",
    "            model_output = self.Bert_representations(**model_input)\n",
    "        \n",
    "        # Get the representation of [CLS]\n",
    "        model_output = model_output.last_hidden_state[:, 0, :]\n",
    "        model_output = self.MLP_layer(model_output)\n",
    "        return model_output\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Base model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = 'sentence-transformers/all-MiniLM-L12-v1'\n",
    "model = STS_model(model_name, device=device, pef_config=PEFT_CONFIG)\n",
    "print('Loaded model to device: ', device)\n",
    "\n",
    "# Load TripletLoss data\n",
    "data_path = './dataset/data.csv'\n",
    "data = get_processed_input_examples_full(data_path)\n",
    "cleaned_data = []\n",
    "for q in data:\n",
    "    if all(isinstance(item, str) for item in q.texts):\n",
    "        cleaned_data.append(q)\n",
    "data = cleaned_data\n",
    "\n",
    "\n",
    "# Load Vis data\n",
    "data_path = './dataset/data.csv'\n",
    "questions, ids, node_names = get_vis_data(data_path=data_path)\n",
    "questions = questions[:256]\n",
    "ids = ids[:256]\n",
    "node_names = node_names[:256]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings from the base model for further comparison\n",
    "bare_model_embeddings = []\n",
    "for q in tqdm(questions):\n",
    "    emb = model(q).detach().cpu().numpy()\n",
    "    bare_model_embeddings.append(emb)   \n",
    "bare_model_embeddings = np.array(bare_model_embeddings).squeeze()\n",
    "bare_model_embeddings_2d = TSNE(n_components=2).fit_transform(bare_model_embeddings)\n",
    "print('bare model embeddings shape: ', bare_model_embeddings.shape)\n",
    "print('bare model embeddings 2d shape: ', bare_model_embeddings_2d.shape)\n",
    "\n",
    "# Compare the bare model embeddings with themselves\n",
    "compare_sactter_plots(bare_model_embeddings_2d, bare_model_embeddings_2d, ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader for triplet texts in bathces\n",
    "class TripletDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, device='cpu', batch_size=None, shuffle=True):\n",
    "        self.data = data\n",
    "        if shuffle:\n",
    "            random.shuffle(self.data)\n",
    "        self.device = device\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = 0\n",
    "        for item in self.data:\n",
    "            for text in item.texts:\n",
    "                self.max_len = max(self.max_len, len(text))\n",
    "        self.batch_size = batch_size\n",
    "        self.batched_data = []\n",
    "        if self.batch_size is not None:\n",
    "            current_batch = []\n",
    "            for i, item in enumerate(self.data):\n",
    "                if i % self.batch_size == 0 and i != 0:\n",
    "                    self.batched_data.append(current_batch)\n",
    "                    current_batch = []\n",
    "                current_batch.append(item.texts)\n",
    "                #TODO: add Last batch with less than batch_size elements\n",
    "            self.batched_data = np.array(self.batched_data)\n",
    "            print('Batched data shape: ', self.batched_data.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.batch_size is not None:\n",
    "            return len(self.batched_data)\n",
    "        else:\n",
    "            return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.batch_size is not None:\n",
    "            batch = self.batched_data[idx]\n",
    "            anchors = batch[:, 0].tolist()\n",
    "            positives = batch[:, 1].tolist()\n",
    "            negatives = batch[:, 2].tolist()\n",
    "            encoded_anchors = self.tokenizer(anchors, padding='max_length', max_length=self.max_len, truncation=True, return_tensors='pt')\n",
    "            encoded_positives = self.tokenizer(positives, padding='max_length', max_length=self.max_len, truncation=True, return_tensors='pt')\n",
    "            encoded_negatives = self.tokenizer(negatives, padding='max_length', max_length=self.max_len, truncation=True, return_tensors='pt')\n",
    "            encoded_anchors.to(self.device)\n",
    "            encoded_positives.to(self.device)\n",
    "            encoded_negatives.to(self.device)\n",
    "            return encoded_anchors, encoded_positives, encoded_negatives\n",
    "        else:\n",
    "            #TODO: implement __getitem__ for single elements\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training parameters\n",
    "batch_size = 4\n",
    "train_dataset = TripletDataset(data, model.tokenizer, device=device, batch_size=batch_size)\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)\n",
    "triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "num_epochs = 5\n",
    "loss = 0\n",
    "epoch=0\n",
    "steps = 0\n",
    "eval_every = 1000\n",
    "total_loss = 0\n",
    "save_model_every = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        tbar = tqdm(train_dataset, unit='batch', desc=f'Epoch {epoch} current loss: {loss} ')\n",
    "        \n",
    "        for input in tbar:\n",
    "                anchor = model(input[0])\n",
    "                positive = model(input[1])\n",
    "                negative = model(input[2])\n",
    "                loss = triplet_loss(anchor, positive, negative)\n",
    "                epoch_loss += loss.item()\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                tbar.set_description(f'Epoch {epoch} current loss: {loss}')\n",
    "\n",
    "                if steps+1 % eval_every == 0:\n",
    "                        avarage_loss = total_loss / eval_every\n",
    "                        total_loss = 0\n",
    "                        print(f'Steps {steps} avarage loss: {avarage_loss}')\n",
    "                        tuned_model_embeddings = []\n",
    "                        for q in tqdm(questions):\n",
    "                                emb = model(q).detach().cpu().numpy()\n",
    "                                tuned_model_embeddings.append(emb)\n",
    "                        tuned_model_embeddings = np.array(tuned_model_embeddings).squeeze()\n",
    "                        tuned_model_embeddings_2d = TSNE(n_components=2).fit_transform(tuned_model_embeddings)\n",
    "                        compare_sactter_plots(bare_model_embeddings_2d, tuned_model_embeddings_2d, ids)\n",
    "\n",
    "                if steps % save_model_every == 0:\n",
    "                        mlp_model = model.MLP_layer\n",
    "                        lora_model = model.Bert_representations\n",
    "\n",
    "                        if not os.path.exists('./models/LoRa'):\n",
    "                                os.makedirs('./models/LoRa')\n",
    "\n",
    "                        torch.save(mlp_model.state_dict(), f'./models/LoRa/mlp_model_{steps}.pth')\n",
    "                        lora_model.save_pretrained(f'./models/LoRa/lora_model_{steps}')\n",
    "                \n",
    "                steps += 1\n",
    "\n",
    "        print(f'Epoch loss: {epoch_loss}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
