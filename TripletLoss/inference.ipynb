{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRa model From HuggingFace Hub...:  ammarnasr/LoRa_all-MiniLM-L12-v1\n",
      "trainable params: 5357568 || all params: 38717568 || trainable%: 13.837563351086514\n",
      "Embeddings loaded from ./embeddings\\ammarnasr_LoRa_all-MiniLM-L12-v1_data.pkl\n",
      "Predicted Group: 5.0 for sentence: What is the best way to learn machine learning?\n",
      "Sentences from the predicted group:\n",
      "['هل بقدر اشتري دولار من البنك مع العلم اني مسافر ولدي تأشيرة وتذكرة طائرة', 'وكم أقصي مبلغ من الدولار الذي استطيع الحصول عليه من البنك', 'ممكن اشتري ريال من البنك والمطلوب؟؟؟', 'داير اشتري دولار انا مسافر', 'ممكن اشتري دولار من البنك؟', 'داير ابدل عملة سودانية لي دولار', 'بستفسر من طريقة شراء الدولار من البنك', 'مطلوب مبلغ 10 الف يورو']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CPU times: total: 2.72 s\n",
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#add magic command to calculate time and compare first and second run times\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from network import STS_model\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "#Set Device\n",
    "global DEVICE\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load Model effciently to avoid loading it every time\n",
    "# global lORA_PEFT_PATH\n",
    "# lORA_PEFT_PATH = 'ammarnasr/LoRa_all-MiniLM-L12-v1'\n",
    "# global MODEL\n",
    "# MODEL = STS_model(lORA_PEFT_PATH, device=DEVICE)\n",
    "\n",
    "\n",
    "def get_inference_dataset(data_path='./TripletLoss/dataset/data.csv', sentences_column='question', labels_column='id'):\n",
    "    '''\n",
    "    Get Sentences and Labels from Data Path\n",
    "    args:\n",
    "        data_path: str\n",
    "        sentences_column: str\n",
    "        labels_column: str\n",
    "    return:\n",
    "        sentences: pd.Series\n",
    "        labels: pd.Series\n",
    "    '''\n",
    "    data = pd.read_csv(data_path)   \n",
    "    data = data.dropna(subset=[sentences_column])\n",
    "    data = data.dropna(subset=[labels_column])\n",
    "    data = data.reset_index(drop=True)\n",
    "    sentences = data[sentences_column]\n",
    "    labels = data[labels_column]\n",
    "    return sentences, labels\n",
    "\n",
    "def predict_group(target_embedding, embeddings, labels):\n",
    "    '''\n",
    "    Predict group for a target embedding\n",
    "    args:\n",
    "        target_embedding: np.array\n",
    "        embeddings: np.array\n",
    "        labels: pd.Series\n",
    "    return:\n",
    "        predicted_group: str\n",
    "    '''\n",
    "    unique_groups = labels.unique()\n",
    "    avarage_group_embeddings = []\n",
    "    for group in unique_groups:\n",
    "        group_indices = labels[labels == group].index\n",
    "        group_embeddings = embeddings[group_indices]\n",
    "        avarage_group_embeddings.append(group_embeddings.mean(axis=0))\n",
    "    avarage_group_embeddings = np.array(avarage_group_embeddings)\n",
    "    distances = cosine_distances(target_embedding, avarage_group_embeddings)\n",
    "    predicted_group = unique_groups[np.argmin(distances)]\n",
    "    return predicted_group\n",
    "\n",
    "\n",
    "def get_all_embeddings(model, sentences):\n",
    "    '''\n",
    "    Get all embeddings for all sentences in the dataset\n",
    "    args:\n",
    "        model: STS_model\n",
    "        sentences: torch.tensor\n",
    "    return:\n",
    "        embeddings: np.array\n",
    "    '''\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for sentence in tqdm(sentences.tolist(), unit='sentence', desc='Getting embeddings'):\n",
    "            embedding = model(sentence).detach().cpu().numpy()\n",
    "            embeddings.append(embedding)\n",
    "    embeddings = np.array(embeddings).squeeze()\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #Set Data Path and Model Path and Embeddings Dir\n",
    "    data_path = './dataset/data.csv'\n",
    "    lora_peft_path = 'ammarnasr/LoRa_all-MiniLM-L12-v1'\n",
    "    emddings_dir = './embeddings'\n",
    "    \n",
    "\n",
    "    #Create Embeddings Path from Data Path and Model Path and Embeddings Dir\n",
    "    embeddings_name = lora_peft_path.replace('/', '_')\n",
    "    data_name = data_path.split('/')[-1].split('.')[0]\n",
    "    embeddings_path = os.path.join(emddings_dir, embeddings_name+'_'+data_name)\n",
    "    embeddings_path = embeddings_path + '.pkl'\n",
    "    \n",
    "    #Create Embeddings Dir if not exists\n",
    "    if not os.path.exists(emddings_dir):\n",
    "        os.makedirs(emddings_dir)\n",
    "\n",
    "    #Get Sentences and Labels from Data Path and Model from Model Path\n",
    "    sentences, labels = get_inference_dataset(data_path)\n",
    "    unique_groups = labels.unique()\n",
    "    model = STS_model(lora_peft_path, device=DEVICE) \n",
    "\n",
    "    #Load Embeddings if exists, else get all embeddings and save them\n",
    "    if os.path.exists(embeddings_path):\n",
    "        with open(embeddings_path, 'rb') as f:\n",
    "            embeddings = pickle.load(f)\n",
    "        print(f'Embeddings loaded from {embeddings_path}')\n",
    "    else:\n",
    "        embeddings = get_all_embeddings(model, sentences)\n",
    "        with open(embeddings_path, 'wb') as f:\n",
    "            pickle.dump(embeddings, f)\n",
    "        print(f'Embeddings saved to {embeddings_path}')\n",
    "\n",
    "\n",
    "    #Predict Group for a target sentence\n",
    "    target_sentence = 'What is the best way to learn machine learning?'\n",
    "    target_embedding = model(target_sentence).detach().cpu().numpy()\n",
    "    predicted_group = predict_group(target_embedding, embeddings, labels)\n",
    "    \n",
    "    #Print Results and Sentences from the predicted group\n",
    "    print(f'Predicted Group: {predicted_group} for sentence: {target_sentence}')\n",
    "    print('Sentences from the predicted group:')\n",
    "    print(sentences[labels==predicted_group].tolist())\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
