{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "181a8e1f-e6ab-4282-b0da-cb0ba41b2630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.7/site-packages (2.169.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.26.154)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.21.6)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (23.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.3.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML==6.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (6.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.7/site-packages (from sagemaker) (3.5.3)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.154 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.29.154)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (4.6.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.14.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->sagemaker) (0.15.7)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema->sagemaker) (65.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2019.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from schema->sagemaker) (0.6.0.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.154->boto3<2.0,>=1.26.131->sagemaker) (1.26.16)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2023.5.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets[s3] in /opt/conda/lib/python3.7/site-packages (2.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (1.21.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (0.15.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (4.13.0)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.7/site-packages (from datasets[s3]) (0.4.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets[s3]) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets[s3]) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets[s3]) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets[s3]) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets[s3]) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets[s3]) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets[s3]) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets[s3]) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets[s3]) (4.6.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets[s3]) (3.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets[s3]) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets[s3]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets[s3]) (2023.5.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets[s3]) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets[s3]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets[s3]) (2019.3)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /opt/conda/lib/python3.7/site-packages (from s3fs->datasets[s3]) (1.29.154)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from botocore>=1.12.91->s3fs->datasets[s3]) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets[s3]) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (4.30.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (4.65.0)\n",
      "Collecting torch>=1.6.0 (from sentence_transformers)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker\n",
    "!pip install transformers\n",
    "!pip install datasets[s3]\n",
    "!pip install torch\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3f26dd7-8847-40b0-977a-5c67190840ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import sagemaker.huggingface\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "pipeline_session = PipelineSession()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "model_package_group_name = f\"SimilarityTestModelRegisterName\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ba33860-c4b0-47d9-8427-05814d4620c2",
   "metadata": {},
   "source": [
    "processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efd337c7-c3db-4487-9a30-1e30b30aa626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "training_input_path = f's3://sagemaker-us-east-1-107408944800/samples/datasets/data.csv'\n",
    "test_input_path = f's3://sagemaker-us-east-1-107408944800/samples/datasets/data.csv'\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m4.xlarge\")\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=training_input_path,\n",
    ")\n",
    "batch_data = ParameterString(\n",
    "    name=\"BatchData\",\n",
    "    default_value=test_input_path,\n",
    ")\n",
    "mse_threshold = ParameterFloat(name=\"MseThreshold\", default_value=6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d8f0f20-c52e-4f78-8da6-7e0ed55bc61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa5938e8-b285-4359-84e8-9d672c66da24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/preprocessing.py\n",
    "\n",
    "import os \n",
    "os.system('pip install datasets[s3]')\n",
    "os.system('pip install transformers')\n",
    "os.system('pip install sentence_transformers')\n",
    "os.system('pip install torch')\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import InputExample\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import boto3\n",
    "\n",
    "\n",
    "class TripletDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, device='cpu', batch_size=10, shuffle=True, max_len=200):\n",
    "        '''\n",
    "        data: pandas dataframe with columns: ['triplet', 'positive_group', 'negative_group']\n",
    "        tokenizer: tokenizer object from transformers library\n",
    "        device: torch device\n",
    "        batch_size: batch size for the dataloader\n",
    "        shuffle: shuffle the data before batching\n",
    "        '''\n",
    "        self.data = data\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        if shuffle:\n",
    "            self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        self.batched_data = []\n",
    "        current_batch = []\n",
    "        for k in tqdm(range(len(self.data)), unit='row', desc='Batching data'):\n",
    "            row = self.data.iloc[k]\n",
    "            item = row['triplet']\n",
    "            current_batch.append(item.texts)\n",
    "            if len(current_batch) == self.batch_size:\n",
    "                self.batched_data.append(current_batch)\n",
    "                current_batch = []\n",
    "        for k in range(self.batch_size - len(current_batch) ):\n",
    "            row = self.data.iloc[k]\n",
    "            item = row['triplet']\n",
    "            current_batch.append(item.texts)\n",
    "        self.batched_data.append(current_batch)\n",
    "        \n",
    "        self.batched_data = np.array(self.batched_data)\n",
    "        self.batched_anchors = []\n",
    "        self.batched_positives = []\n",
    "        self.batched_negatives = []\n",
    "        \n",
    "        for i in tqdm(range(len(self.batched_data)), unit='batch', desc='Tokenizing data'):\n",
    "            batch = self.batched_data[i]\n",
    "            anchors = batch[:, 0].tolist()\n",
    "            positives = batch[:, 1].tolist()\n",
    "            negatives = batch[:, 2].tolist()\n",
    "            encoded_anchors   = self.tokenizer(anchors  , padding='max_length', max_length=self.max_len, truncation=True, return_tensors='pt')\n",
    "            encoded_positives = self.tokenizer(positives, padding='max_length', max_length=self.max_len, truncation=True, return_tensors='pt')\n",
    "            encoded_negatives = self.tokenizer(negatives, padding='max_length', max_length=self.max_len, truncation=True, return_tensors='pt')\n",
    "            self.batched_anchors.append(encoded_anchors)\n",
    "            self.batched_positives.append(encoded_positives)\n",
    "            self.batched_negatives.append(encoded_negatives)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batched_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoded_anchors   = self.batched_anchors[idx]\n",
    "        encoded_positives = self.batched_positives[idx]\n",
    "        encoded_negatives = self.batched_negatives[idx]\n",
    "        encoded_anchors.to(self.device)\n",
    "        encoded_positives.to(self.device)\n",
    "        encoded_negatives.to(self.device)\n",
    "        return encoded_anchors, encoded_positives, encoded_negatives\n",
    "\n",
    "def get_sentence_id_label_df(path='./dataset/data.csv'):\n",
    "    df = pd.read_csv(path)\n",
    "    ids_to_labels_dict = get_ids_to_labels_dict(df)\n",
    "    df = clean_data(df)\n",
    "    #Loop over all sentences\n",
    "    sentences = df['question'].tolist()\n",
    "    ids = df['id'].tolist()\n",
    "    labels = [ids_to_labels_dict[id] for id in ids]\n",
    "    data = {'sentence': sentences, 'id': ids, 'label': labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def get_ids_to_labels_dict(data):\n",
    "    ids_to_labels_dict = {}\n",
    "    grouped = data.groupby('id')\n",
    "    for name, group in grouped:\n",
    "        labels = group['node_name'].tolist()\n",
    "        for label in labels:\n",
    "            if isinstance(label, str):\n",
    "                ids_to_labels_dict[name] = label\n",
    "            if name in ids_to_labels_dict:\n",
    "                break\n",
    "        if name not in ids_to_labels_dict:\n",
    "            ids_to_labels_dict[name] = f'unknown_{name}'\n",
    "    return ids_to_labels_dict\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def get_dataset(bucket, data_key, downsample_flag=True):\n",
    "    data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "    df = pd.read_csv(data_location)\n",
    "    df = clean_data(df)\n",
    "    train, test = train_test_split(df, test_size=0.2)\n",
    "    # train = create_triplets(train)\n",
    "    # train = remove_duplicates(train)\n",
    "    # if downsample_flag:\n",
    "    #     train = downsample(train)\n",
    "    return train, test\n",
    "\n",
    "def create_triplets(data):\n",
    "    detailed_dict ={'triplet': [], 'positive_group': [], 'negative_group': [] }\n",
    "    grouped = data.groupby('id')\n",
    "\n",
    "    for name, group in tqdm(grouped, unit='group', desc='Creating triplets'):\n",
    "        questions = group['question'].tolist()\n",
    "        for i in range(len(questions)-1):\n",
    "            anchor = questions[i]\n",
    "\n",
    "            for j in range(len(questions)-1):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                positive = questions[j]\n",
    "\n",
    "                for other_name, other_group in grouped:\n",
    "                    if name == other_name:\n",
    "                        continue\n",
    "                    negatives = other_group['question'].tolist()\n",
    "\n",
    "                    for negative in negatives:\n",
    "                        triplet = InputExample(texts=[anchor, positive, negative])\n",
    "                        detailed_dict['triplet'].append(triplet)\n",
    "                        detailed_dict['positive_group'].append(name)\n",
    "                        detailed_dict['negative_group'].append(other_name)\n",
    "\n",
    "    data = pd.DataFrame(detailed_dict)\n",
    "    return data\n",
    "\n",
    "def downsample(data):\n",
    "    min_len = data.positive_group.value_counts().min()\n",
    "    grouped = data.groupby('positive_group')\n",
    "    data = pd.concat([group.sample(min_len) for name, group in grouped])\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "def clean_data(data):\n",
    "    data = data.dropna(subset=['question'])\n",
    "    data = data.dropna(subset=['id'])\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "def remove_duplicates(data):\n",
    "    #remove duplicate rows from the dataframe\n",
    "    data = data.drop_duplicates(subset=['triplet'])\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "    \n",
    "    \n",
    "    train, test = get_dataset(bucket = \"sagemaker-us-east-1-107408944800\", data_key = \"samples/datasets/data.csv\")\n",
    "        \n",
    "    pd.DataFrame(train).to_csv(f\"{base_dir}/train/train.csv\")\n",
    "\n",
    "    pd.DataFrame(test).to_csv(f\"{base_dir}/test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b82b12e3-05ae-4862-8b13-35f014f5d193",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "\n",
    "framework_version = \"1.2-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-abalone-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "432acf2b-129c-4dbc-95f9-299b0542d63e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        # ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"code/preprocessing.py\",\n",
    ")\n",
    "\n",
    "preprocessing_step = ProcessingStep(name=\"SimilarityPreprocessing\", step_args=processor_args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58637c15-c891-4f17-a4ca-cb235f2824d4",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "342e7b8f-b328-40f3-91d5-363327c8067e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/train.py\n",
    "\n",
    "import os \n",
    "os.system('pip install datasets[s3]')\n",
    "os.system('pip install transformers')\n",
    "os.system('pip install sentence_transformers')\n",
    "os.system('pip install torch')\n",
    "os.system('pip install sklearn')\n",
    "os.system('pip install peft')\n",
    "os.system('pip install wandb')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import csv\n",
    "import gzip\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from peft import LoraConfig, get_peft_model, PeftConfig, PeftModel\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import InputExample, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_dsiatances_from_embeddings(embeddings, labels):\n",
    "    group_distances = []\n",
    "    total_distances = []\n",
    "    all_res = {'group_id': [], 'inner_distance': [], 'across_distance': []}\n",
    "    unique_groups = labels.unique()\n",
    "\n",
    "    for group in unique_groups:\n",
    "        # Calculate pairwise cosine distances within the group\n",
    "        group_indices = labels[labels == group].index\n",
    "        group_embeddings = embeddings[group_indices]\n",
    "        group_distance = cosine_distances(group_embeddings).mean()\n",
    "        group_distances.append(group_distance)\n",
    "        \n",
    "        # Calculate pairwise cosine distances across groups\n",
    "        other_indices = labels[labels != group].index\n",
    "        other_embeddings = embeddings[other_indices]\n",
    "        total_distance = cosine_distances(group_embeddings, other_embeddings).mean()\n",
    "        total_distances.append(total_distance)\n",
    "\n",
    "        # Append the results to the dictionary\n",
    "        all_res['group_id'].append(group)\n",
    "        all_res['inner_distance'].append(group_distance)\n",
    "        all_res['across_distance'].append(total_distance)\n",
    "\n",
    "    # Calculate the average distances\n",
    "    average_group_distance = sum(group_distances) / len(group_distances)\n",
    "    average_total_distance = sum(total_distances) / len(total_distances)\n",
    "    all_res['average_inner_distance'] = average_group_distance\n",
    "    all_res['average_across_distance'] = average_total_distance\n",
    "\n",
    "    print(\"Average inner_distance  within groups(The lower  the better):\", average_group_distance)\n",
    "    print(\"Average across_distance across groups(The higher the better):\", average_total_distance)\n",
    "    return all_res\n",
    "\n",
    "def calculate_accuracy_from_embeddings(embeddings, labels):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    unique_groups = labels.unique()\n",
    "    avarage_group_embeddings = []\n",
    "    for group in unique_groups:\n",
    "        group_indices = labels[labels == group].index\n",
    "        group_embeddings = embeddings[group_indices]\n",
    "        avarage_group_embeddings.append(group_embeddings.mean(axis=0))\n",
    "    avarage_group_embeddings = np.array(avarage_group_embeddings)\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        total += 1\n",
    "        distances = cosine_distances([embedding], avarage_group_embeddings)\n",
    "        if np.argmin(distances)+1 == labels[i]:\n",
    "            correct += 1\n",
    "\n",
    "    \n",
    "    acc  = correct / total\n",
    "    print(f'Accuracy: {acc*100:.2f}%')\n",
    "    return acc*100\n",
    "\n",
    "\n",
    "def get_sent_embeddings(model, sentences):\n",
    "    return model.encode(sentences, show_progress_bar=True)\n",
    "\n",
    "def get_node_name(id, data_path = os.environ[\"SM_CHANNEL_TRAIN\"]  + \"/train.csv\"):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df_labels = df[df['node_name'].notnull()][['id', 'node_name']]\n",
    "    df_labels.fillna(7.0, inplace=True)\n",
    "    return df_labels[df_labels['id'] == id]['node_name'].values[0]\n",
    "\n",
    "def get_vis_data(data_path = './TripletLoss/dataset/data.csv'):\n",
    "    df = pd.read_csv(data_path)    \n",
    "    df.dropna(subset=['question'], inplace=True)\n",
    "    df.dropna(subset=['id'], inplace=True)\n",
    "    ids_with_count_greater_than_16 = df.id.value_counts()[df.id.value_counts() > 2].index.tolist()\n",
    "    df = df[df['id'].isin(ids_with_count_greater_than_16)]\n",
    "    questions = df['question'].tolist()\n",
    "    ids = df['id'].tolist()\n",
    "    node_names = [get_node_name(id, data_path=data_path) for id in ids]\n",
    "\n",
    "    return questions, ids, node_names\n",
    "\n",
    "def get_2d_embeddings(model_path, questions):\n",
    "    model = SentenceTransformer(model_path)\n",
    "    embeddings = get_sent_embeddings(model, questions)\n",
    "    embeddings_2d = TSNE(n_components=2).fit_transform(embeddings)\n",
    "    return embeddings_2d\n",
    "\n",
    "\n",
    "\n",
    "def compare_sactter_plots(embeddings_2d_1, embeddings_2d_2, ids,save_fig_name=None,title1= 'bare model', title2 = 'tuned model', cmap_name='tab20', show=True):\n",
    "    unique_ids = set(ids)\n",
    "    colors = plt.cm.get_cmap(cmap_name, len(unique_ids))\n",
    "    id_color_map = {id: colors(i) for i, id in enumerate(unique_ids)}\n",
    "    # Visualize the embeddings colored by their ids with a legend of node names\n",
    "    if embeddings_2d_2 is not None:\n",
    "        fig, ax = plt.subplots(2, figsize=(8, 10))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        ax = [ax]\n",
    "\n",
    "    scatter1 = ax[0].scatter(embeddings_2d_1[:, 0], embeddings_2d_1[:, 1], c=ids, cmap=cmap_name)\n",
    "    ax[0].set_title(title1)\n",
    "\n",
    "    if embeddings_2d_2 is not None:\n",
    "        scatter2 = ax[1].scatter(embeddings_2d_2[:, 0], embeddings_2d_2[:, 1], c=ids, cmap=cmap_name)\n",
    "        ax[1].set_title(title2)\n",
    "\n",
    "    legend_labels = [plt.Line2D([], [], marker='o', color=id_color_map[id], markersize=5, label=get_node_name(id)) for id in unique_ids]\n",
    "    fig.legend(handles=legend_labels, loc='center', bbox_to_anchor=(0.5, 1.05), ncol=3)\n",
    "    plt.tight_layout()\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    if save_fig_name is not None:\n",
    "        plt.savefig(save_fig_name)\n",
    "\n",
    "\n",
    "\n",
    "def show_comparison_plot(tuned_model_name='./TripletLoss/models/sbert_model', show=True):\n",
    "    bare_model_name = 'all-MiniLM-L6-v2'\n",
    "\n",
    "    questions, ids, node_names = get_vis_data()\n",
    "\n",
    "    bare_embeddings_2d = get_2d_embeddings(bare_model_name, questions)\n",
    "    tuned_embeddings_2d = get_2d_embeddings(tuned_model_name, questions)\n",
    "    save_fig_name = f'./figs/{tuned_model_name.split(\"/\")[-1]}.png'\n",
    "    compare_sactter_plots(bare_embeddings_2d, tuned_embeddings_2d, ids,save_fig_name=save_fig_name, title1= 'bare model', title2 = 'tuned model', cmap_name='tab10', show=show)\n",
    "\n",
    "\n",
    "def get_sts_benchmark_data():\n",
    "    # Download dataset if needed\n",
    "    sts_dataset_path = './TripletLoss/dataset/stsbenchmark.tsv.gz'\n",
    "    if not os.path.exists(sts_dataset_path):\n",
    "        util.http_get('https://sbert.net/datasets/stsbenchmark.tsv.gz', sts_dataset_path)\n",
    "    test_samples = []\n",
    "    with gzip.open(sts_dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "        reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "        for row in reader:\n",
    "            if row['split'] == 'test':\n",
    "                score = float(row['score']) / 5.0 #Normalize score to range 0 ... 1\n",
    "                test_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score))\n",
    "    return test_samples\n",
    "\n",
    "\n",
    "def print_sts_benchmark_scores(tuned_model_name='./TripletLoss/models/sbert_model', print_bare_model_scores=False):\n",
    "    test_samples = get_sts_benchmark_data()\n",
    "    x = [sample.texts for sample in test_samples]\n",
    "    test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, batch_size=16, name='sts-test')\n",
    "\n",
    "\n",
    "    if print_bare_model_scores:\n",
    "        bare_model_name = 'all-MiniLM-L6-v2'\n",
    "        bare_model = SentenceTransformer(bare_model_name)\n",
    "        print(f'{\"=\"*10} {bare_model_name} Bare Model Reseluts {\"=\"*10}')\n",
    "        bare_res = test_evaluator(bare_model)\n",
    "        print(bare_res)\n",
    "\n",
    "\n",
    "\n",
    "    tuned_model = SentenceTransformer(tuned_model_name)\n",
    "    print(f'{\"=\"*10} {tuned_model_name} Tuned Model Reseluts {\"=\"*10}')\n",
    "    res = test_evaluator(tuned_model)\n",
    "    print(res)\n",
    "\n",
    "    #append the results to a file\n",
    "    file_name = 'sts_benchmark_scores.csv'\n",
    "\n",
    "\n",
    "    if not os.path.exists(file_name):\n",
    "        with open(file_name, 'w') as f:\n",
    "            f.write('model_name,socre\\n')\n",
    "    \n",
    "    with open(file_name, 'a') as f:\n",
    "        f.write(f'{tuned_model_name},{res}\\n')\n",
    "\n",
    "    print(f'Saved the results to {file_name}')\n",
    "\n",
    "def get_average_distances(model_name = 'all-MiniLM-L6-v2'):\n",
    "\n",
    "    # Load the dataframe\n",
    "    \n",
    "    # Get the data\n",
    "    data_path = './TripletLoss/dataset/data.csv'\n",
    "    df = pd.read_csv(data_path)\n",
    "    df = df[['question', 'id']]\n",
    "\n",
    "    # drop rows with nan values\n",
    "    df = df.dropna()\n",
    "\n",
    "    #Reset the index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # rename columns to sentences and labels\n",
    "    df.columns = ['sentence', 'label']\n",
    "\n",
    "    # Load the sentence transformer model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Generate sentence embeddings\n",
    "    embeddings = model.encode(df['sentence'].tolist(), show_progress_bar=True)\n",
    "\n",
    "\n",
    "    # Calculate average distances within and across groups\n",
    "    group_distances = []\n",
    "    total_distances = []\n",
    "    all_res = {\n",
    "        'group_id': [],\n",
    "        'group_distance': [],\n",
    "        'total_distance': [],\n",
    "        'model_name': []\n",
    "    }\n",
    "    unique_groups = df['label'].unique()\n",
    "\n",
    "    for group in unique_groups:\n",
    "        group_indices = df[df['label'] == group].index\n",
    "        group_embeddings = embeddings[group_indices]\n",
    "        \n",
    "        # Calculate pairwise cosine distances within the group\n",
    "        group_distance = cosine_distances(group_embeddings).mean()\n",
    "        group_distances.append(group_distance)\n",
    "        \n",
    "        # Calculate pairwise cosine distances across groups\n",
    "        other_indices = df[df['label'] != group].index\n",
    "        other_embeddings = embeddings[other_indices]\n",
    "        total_distance = cosine_distances(group_embeddings, other_embeddings).mean()\n",
    "        total_distances.append(total_distance)\n",
    "\n",
    "        all_res['group_id'].append(group)\n",
    "        all_res['group_distance'].append(group_distance)\n",
    "        all_res['total_distance'].append(total_distance)\n",
    "        all_res['model_name'].append(model_name)\n",
    "\n",
    "    # Calculate the average distances\n",
    "    average_group_distance = sum(group_distances) / len(group_distances)\n",
    "    average_total_distance = sum(total_distances) / len(total_distances)\n",
    "\n",
    "    print(\"Average distance within groups:\", average_group_distance)\n",
    "    print(\"Average distance across groups:\", average_total_distance)\n",
    "\n",
    "    return average_group_distance, average_total_distance, all_res\n",
    "\n",
    "def save_distances(tuned_model_name='./TripletLoss/models/sbert_model', print_bare_model_scores=False):\n",
    "\n",
    "    if print_bare_model_scores:\n",
    "        bare_model_name = 'all-MiniLM-L6-v2'\n",
    "        print(f'Caculating average distances for {bare_model_name}')\n",
    "        _, _, bare_res = get_average_distances(bare_model_name)\n",
    "        print('='*10)\n",
    "        bare_res_df = pd.DataFrame(bare_res)\n",
    "\n",
    "\n",
    "    print(f'Caculating average distances for {tuned_model_name}')\n",
    "    _, _, tuned_res = get_average_distances(tuned_model_name)\n",
    "    tuned_res_df = pd.DataFrame(tuned_res)\n",
    "\n",
    "\n",
    "    file_name = f'average_distances.csv'\n",
    "    if not os.path.exists(file_name):\n",
    "        #save dataframes to csv\n",
    "        tuned_res_df.to_csv(file_name, index=False)\n",
    "    \n",
    "    else:\n",
    "        #read the file and append the new results\n",
    "        df = pd.read_csv(file_name)\n",
    "        df = df.append(tuned_res_df, ignore_index=True)\n",
    "        df.to_csv(file_name, index=False)\n",
    "\n",
    "    print(f'Saved the results to {file_name}')\n",
    "\n",
    "\n",
    "class TripletDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, device='cpu', batch_size=10, shuffle=True, max_len=200):\n",
    "        '''\n",
    "        data: pandas dataframe with columns: ['triplet', 'positive_group', 'negative_group']\n",
    "        tokenizer: tokenizer object from transformers library\n",
    "        device: torch device\n",
    "        batch_size: batch size for the dataloader\n",
    "        shuffle: shuffle the data before batching\n",
    "        '''\n",
    "        self.data = data\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        if shuffle:\n",
    "            self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        self.batched_data = []\n",
    "        current_batch = []\n",
    "        for k in tqdm(range(len(self.data)), unit='row', desc='Batching data'):\n",
    "            row = self.data.iloc[k]\n",
    "            item = row['triplet']\n",
    "            # print(item)\n",
    "            current_batch.append(item.texts)\n",
    "            # current_batch.append(item)\n",
    "            if len(current_batch) == self.batch_size:\n",
    "                self.batched_data.append(current_batch)\n",
    "                current_batch = []\n",
    "        for k in range(self.batch_size - len(current_batch) ):\n",
    "            row = self.data.iloc[k]\n",
    "            item = row['triplet']\n",
    "            print(item)\n",
    "            current_batch.append(item.texts)\n",
    "            # current_batch.append(item)\n",
    "            \n",
    "        self.batched_data.append(current_batch)\n",
    "        \n",
    "        self.batched_data = np.array(self.batched_data)\n",
    "        self.batched_anchors = []\n",
    "        self.batched_positives = []\n",
    "        self.batched_negatives = []\n",
    "        \n",
    "        for i in tqdm(range(len(self.batched_data)), unit='batch', desc='Tokenizing data'):\n",
    "            batch = self.batched_data[i]\n",
    "            anchors = batch[:, 0].tolist()\n",
    "            positives = batch[:, 1].tolist()\n",
    "            negatives = batch[:, 2].tolist()\n",
    "            encoded_anchors   = self.tokenizer(anchors  , padding='max_length', max_length=self.max_len, truncation=True, return_tensors='pt')\n",
    "            encoded_positives = self.tokenizer(positives, padding='max_length', max_length=self.max_len, truncation=True, return_tensors='pt')\n",
    "            encoded_negatives = self.tokenizer(negatives, padding='max_length', max_length=self.max_len, truncation=True, return_tensors='pt')\n",
    "            self.batched_anchors.append(encoded_anchors)\n",
    "            self.batched_positives.append(encoded_positives)\n",
    "            self.batched_negatives.append(encoded_negatives)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batched_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoded_anchors   = self.batched_anchors[idx]\n",
    "        encoded_positives = self.batched_positives[idx]\n",
    "        encoded_negatives = self.batched_negatives[idx]\n",
    "        encoded_anchors.to(self.device)\n",
    "        encoded_positives.to(self.device)\n",
    "        encoded_negatives.to(self.device)\n",
    "        return encoded_anchors, encoded_positives, encoded_negatives\n",
    "\n",
    "def get_sentence_id_label_df(path=os.environ[\"SM_CHANNEL_TRAIN\"]  + \"/train.csv\"):\n",
    "    df = pd.read_csv(path)\n",
    "    ids_to_labels_dict = get_ids_to_labels_dict(df)\n",
    "    df = clean_data(df)\n",
    "    #Loop over all sentences\n",
    "    sentences = df['question'].tolist()\n",
    "    ids = df['id'].tolist()\n",
    "    labels = [ids_to_labels_dict[id] for id in ids]\n",
    "    data = {'sentence': sentences, 'id': ids, 'label': labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def get_ids_to_labels_dict(data):\n",
    "    ids_to_labels_dict = {}\n",
    "    grouped = data.groupby('id')\n",
    "    for name, group in grouped:\n",
    "        labels = group['node_name'].tolist()\n",
    "        for label in labels:\n",
    "            if isinstance(label, str):\n",
    "                ids_to_labels_dict[name] = label\n",
    "            if name in ids_to_labels_dict:\n",
    "                break\n",
    "        if name not in ids_to_labels_dict:\n",
    "            ids_to_labels_dict[name] = f'unknown_{name}'\n",
    "    return ids_to_labels_dict\n",
    "\n",
    "def get_dataset(path=os.environ[\"SM_CHANNEL_TRAIN\"]  + \"/train.csv\", downsample_flag=True):\n",
    "    df = pd.read_csv(path)\n",
    "    df = clean_data(df)\n",
    "    df = create_triplets(df)\n",
    "    df = remove_duplicates(df)\n",
    "    if downsample_flag:\n",
    "        df = downsample(df)\n",
    "    return df\n",
    "\n",
    "def create_triplets(data):\n",
    "    detailed_dict ={'triplet': [], 'positive_group': [], 'negative_group': [] }\n",
    "    grouped = data.groupby('id')\n",
    "\n",
    "    for name, group in tqdm(grouped, unit='group', desc='Creating triplets'):\n",
    "        questions = group['question'].tolist()\n",
    "        for i in range(len(questions)-1):\n",
    "            anchor = questions[i]\n",
    "\n",
    "            for j in range(len(questions)-1):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                positive = questions[j]\n",
    "\n",
    "                for other_name, other_group in grouped:\n",
    "                    if name == other_name:\n",
    "                        continue\n",
    "                    negatives = other_group['question'].tolist()\n",
    "\n",
    "                    for negative in negatives:\n",
    "                        triplet = InputExample(texts=[anchor, positive, negative])\n",
    "                        detailed_dict['triplet'].append(triplet)\n",
    "                        detailed_dict['positive_group'].append(name)\n",
    "                        detailed_dict['negative_group'].append(other_name)\n",
    "\n",
    "    data = pd.DataFrame(detailed_dict)\n",
    "    return data\n",
    "\n",
    "def downsample(data):\n",
    "    min_len = data.positive_group.value_counts().min()\n",
    "    grouped = data.groupby('positive_group')\n",
    "    data = pd.concat([group.sample(min_len) for name, group in grouped])\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "def clean_data(data):\n",
    "    data = data.dropna(subset=['question'])\n",
    "    data = data.dropna(subset=['id'])\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "def remove_duplicates(data):\n",
    "    data = data.drop_duplicates(subset=['triplet'])\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class STS_model(nn.Module): \n",
    "    def __init__(self, model_path, device='cpu', pef_config=None, add_bert=True): \n",
    "        super(STS_model, self).__init__() \n",
    "        self.device = device\n",
    "        self.add_bert = add_bert\n",
    "        if add_bert:\n",
    "            self.Bert_representations, self.tokenizer = get_Bert_representations_model(model_path, pef_config)\n",
    "            self.Bert_representations.train(mode=True)\n",
    "            self.Bert_representations.to(device)\n",
    "\n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    def forward(self, model_input): \n",
    "      # Tokenize sentences if input is a string or a list of strings\n",
    "        if isinstance(model_input, str) or (isinstance(model_input, list) and isinstance(model_input[0], str)):\n",
    "            model_input = self.tokenizer(model_input, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "            model_input = model_input.to(self.device)\n",
    "        model_output = self.Bert_representations(**model_input)\n",
    "        sentence_embeddings = self.mean_pooling(model_output, model_input['attention_mask'])\n",
    "        return sentence_embeddings\n",
    "    \n",
    "\n",
    "def get_sts_model(model_path, device='cpu', pef_config=None):\n",
    "    model = STS_model(model_path, device, pef_config)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_Bert_representations_model(model_path, pef_config=None):\n",
    "    lower_case_model_path = model_path.lower()\n",
    "    if 'lora' in lower_case_model_path:\n",
    "        # get LoRa model and lora config from model_path\n",
    "        print('Loading LoRa model From HuggingFace Hub...: ', model_path)\n",
    "        config = PeftConfig.from_pretrained(model_path)\n",
    "        bert = AutoModel.from_pretrained(config.base_model_name_or_path)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "        bert = PeftModel.from_pretrained(bert, model_path)\n",
    "        for name, param in bert.named_parameters():\n",
    "            if 'lora' in name:\n",
    "                param.requires_grad = True\n",
    "        bert.print_trainable_parameters()\n",
    "    elif pef_config is not None:\n",
    "        print('Loading Peft model From HuggingFace Hub...: ', model_path)\n",
    "        bert = AutoModel.from_pretrained(model_path)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        bert = get_peft_model(bert, pef_config)\n",
    "        bert.print_trainable_parameters()\n",
    "    else:\n",
    "        print('Loading Bert model From HuggingFace Hub...: ', model_path)\n",
    "        bert = AutoModel.from_pretrained(model_path)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    return bert, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "def main(args_dict, use_argparse=False):\n",
    "    default_args_dict = {\n",
    "        'model_path': 'ammarnasr/LoRa_all-MiniLM-L12-v1',\n",
    "        'data_path': os.environ[\"SM_CHANNEL_TRAIN\"] + \"/train.csv\",\n",
    "        'device': 'cuda',\n",
    "        'peft_config': None,\n",
    "        'batch_size': 16,\n",
    "        'lr': 1e-5,\n",
    "        'triplet_loss': None,\n",
    "        'num_epochs': 10,\n",
    "        'max_len': 200,\n",
    "        'eval_every': 150,\n",
    "        'save_model_every': 500,\n",
    "        'shuffle': True,\n",
    "        'eval_data_path':  os.environ[\"SM_CHANNEL_TEST\"] + \"/test.csv\",\n",
    "        'save_model_path': './models/LoRa',\n",
    "        'model_save_name': None,\n",
    "        'wandb_project_name': \"Similarity_api\"\n",
    "    }\n",
    "    for key in default_args_dict.keys():\n",
    "        if key not in args_dict.keys():\n",
    "            args_dict[key] = default_args_dict[key]\n",
    "\n",
    "    #Pretty print args\n",
    "    print('Arguments:')\n",
    "    for key in args_dict.keys():\n",
    "        print(f'{key}: {args_dict[key]}')\n",
    "\n",
    "\n",
    "    train(**args_dict)\n",
    "\n",
    "    \n",
    "\n",
    "def train(model_path, data_path= os.environ[\"SM_CHANNEL_TRAIN\"]  + \"/train.csv\", device='cpu', peft_config=None,\n",
    "          batch_size=16, lr=1e-5, triplet_loss=None, num_epochs=5, max_len=100,\n",
    "          eval_every=100,save_model_every=1000, shuffle=True, eval_data_path= os.environ[\"SM_CHANNEL_TEST\"],\n",
    "          save_model_path= os.environ[\"SM_MODEL_DIR\"], model_save_name=None, wandb_project_name=None):\n",
    "    \n",
    "    print('Loading model...')\n",
    "    model = get_sts_model(model_path, device, peft_config)\n",
    "    tokenizer = model.tokenizer\n",
    "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    if not os.path.exists(save_model_path):\n",
    "        os.makedirs(save_model_path)\n",
    "    if model_save_name is None:\n",
    "        model_save_name = model_path.split('/')[-1]\n",
    "    if triplet_loss is None:\n",
    "        triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "    if eval_data_path is None:\n",
    "        eval_data_path = data_path\n",
    "    if wandb_project_name is None:\n",
    "        wandb_project_name = model_save_name+'-tracking'\n",
    "\n",
    "    # data_df = pd.read_csv(data_path)\n",
    "    # eval_data_df = get_sentence_id_label_df(eval_data_path)\n",
    "    # sentences = eval_data_df['sentence']\n",
    "    # labels = eval_data_df['id']\n",
    "    \n",
    "    data_df = get_dataset(data_path)\n",
    "    eval_data_df = get_sentence_id_label_df(eval_data_path)\n",
    "    sentences = eval_data_df['sentence']\n",
    "    labels = eval_data_df['id']\n",
    "\n",
    "    print('Initializing wandb...')\n",
    "    wandb.login(key = \"af0ebd78dadd977aadb9b94cc811dc60924219fc\")\n",
    "    wandb.init(project=wandb_project_name)\n",
    "    wandb.config.update(\n",
    "        {\n",
    "            'model_path': model_path,\n",
    "            'data_path': data_path,\n",
    "            'device': device,\n",
    "            'LoRa_Rank': peft_config.r,\n",
    "            'LoRa_Alpha': peft_config.lora_alpha,\n",
    "            'LoRa_Dropout': peft_config.lora_dropout,\n",
    "            'LoRa_Target_Modules': peft_config.target_modules,\n",
    "            'batch_size': batch_size,\n",
    "            'lr': lr,\n",
    "            'triplet_loss': triplet_loss,\n",
    "            'num_epochs': num_epochs,\n",
    "            'max_len': max_len,\n",
    "            'eval_every': eval_every,\n",
    "            'save_model_every': save_model_every,\n",
    "            'shuffle': shuffle,\n",
    "            'eval_data_path': eval_data_path,\n",
    "            'save_model_path': save_model_path,\n",
    "            'model_save_name': model_save_name,\n",
    "            'wandb_project_name': wandb_project_name\n",
    "        }\n",
    "    )\n",
    "    wandb.watch(model)\n",
    "\n",
    "\n",
    "\n",
    "    print('Training model...')\n",
    "    epochs_tbar = tqdm(range(num_epochs), unit='epoch')\n",
    "    steps = 0\n",
    "    accuracy = 0\n",
    "    for epoch in epochs_tbar:\n",
    "        train_dataset = TripletDataset(data_df, tokenizer=tokenizer, device=device, batch_size=batch_size, shuffle=shuffle, max_len=max_len)\n",
    "        epoch_steps = 0\n",
    "        accumelated_loss = 0\n",
    "        batches_tbar = tqdm(train_dataset, unit='batch')\n",
    "        for input in batches_tbar:\n",
    "                steps += 1\n",
    "                epoch_steps += 1\n",
    "                anchor = model(input[0])\n",
    "                positive = model(input[1])\n",
    "                negative = model(input[2])\n",
    "                loss = triplet_loss(anchor, positive, negative)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                accumelated_loss += loss.item()\n",
    "\n",
    "                batches_tbar.set_description(f'Batch {epoch_steps}/{len(train_dataset)} | Loss: {loss.item():.2f}')\n",
    "                batches_tbar.refresh()\n",
    "\n",
    "                epochs_tbar.set_description(f'Epoch {epoch+1}/{num_epochs} | Average loss: {accumelated_loss/epoch_steps:.2f} | Accuracy: {accuracy:.2f}')\n",
    "                epochs_tbar.refresh()\n",
    "\n",
    "                wandb.log({'loss': loss.item()})\n",
    "                if (steps % eval_every == 0) or (epoch_steps == len(train_dataset)):\n",
    "                    print('Evaluating model')\n",
    "                    embeddings = []\n",
    "                    for sentence in tqdm(sentences, unit='sentence', desc='Generating embeddings'):\n",
    "                        embedding = model(sentence).detach().cpu().numpy()\n",
    "                        embeddings.append(embedding)\n",
    "                    embeddings = np.array(embeddings).squeeze()\n",
    "                    all_res = calculate_dsiatances_from_embeddings(embeddings, labels)\n",
    "                    average_inner_distance  = all_res['average_inner_distance']\n",
    "                    average_across_distance =all_res['average_across_distance']\n",
    "                    accuracy = calculate_accuracy_from_embeddings(embeddings, labels)\n",
    "\n",
    "                    wandb.log({'average_inner_distance': average_inner_distance})\n",
    "                    wandb.log({'average_across_distance': average_across_distance})\n",
    "                    wandb.log({'accuracy': accuracy})\n",
    "                    \n",
    "\n",
    "                if (steps % save_model_every == 0) or (epoch_steps == len(train_dataset)):\n",
    "                    print('Saving model')\n",
    "                    # lora_save_path = f'./models/LoRa/lora_model_{short_model_name}_{steps}'\n",
    "                    lora_save_path = f'{save_model_path}/lora_{model_save_name}_{steps}'\n",
    "                    lora_model = model.Bert_representations\n",
    "                    lora_model.save_pretrained(lora_save_path)\n",
    "                    # print('Pushing model to hub')\n",
    "                    # hub_model_name = f'LoRa_{model_save_name}'\n",
    "                    # lora_model.push_to_hub(hub_model_name)\n",
    "                    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #check length of sys.argv\n",
    "    # if len(sys.argv) <= 1:\n",
    "    print('No arguments were given, using default arguments')\n",
    "\n",
    "    rank = 64\n",
    "    peft_config = LoraConfig(inference_mode=False,\n",
    "                r=rank,\n",
    "                lora_alpha=rank*2,\n",
    "                lora_dropout=0.05,\n",
    "                target_modules=['value','query','key', 'dense']\n",
    "                )\n",
    "    main({'peft_config': peft_config}, use_argparse=False)\n",
    "    # else:\n",
    "    #     print('Arguments were given, using given arguments')\n",
    "    #     main({}, use_argparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2041df-c965-4971-ba38-357402c6a5c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "834252b9-325c-49fe-99ab-1ec9d6182c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'epochs': 1,\n",
    "                 'train_batch_size': 32,\n",
    "                 'model_name':'distilbert-base-uncased'\n",
    "                 }\n",
    "\n",
    "s3_input_train = TrainingInput(\n",
    "s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri, \n",
    "content_type=\"arrow\", \n",
    "s3_data_type=\"S3Prefix\"\n",
    ")\n",
    "\n",
    "s3_input_test = TrainingInput(\n",
    "s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "content_type=\"arrow\",\n",
    "s3_data_type=\"S3Prefix\"\n",
    ")\n",
    "\n",
    "\n",
    "similarity_estimator = HuggingFace(entry_point='train.py',\n",
    "                            source_dir='./code',\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            instance_count=1,\n",
    "                            role=role,\n",
    "                            transformers_version='4.26',\n",
    "                            pytorch_version='1.13',\n",
    "                            py_version='py39',\n",
    "                            sagemaker_session=pipeline_session,\n",
    "                            hyperparameters = hyperparameters)\n",
    "train_args = similarity_estimator.fit({'train': s3_input_train, 'test': s3_input_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8282303b-450d-4f2f-bb87-503beb3184b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"SimilarityTrain\",\n",
    "    step_args=train_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4ab7f42-e040-4c84-b873-06b306285659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline_name = f\"SimilarityPipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        batch_data,\n",
    "        mse_threshold,\n",
    "    ],\n",
    "    steps=[preprocessing_step, step_train],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11960671-e5b8-4f72-bd66-8228ad321803",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:107408944800:pipeline/SimilarityPipeline',\n",
       " 'ResponseMetadata': {'RequestId': 'a891c152-af47-4e30-9011-1beb2f08aa51',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a891c152-af47-4e30-9011-1beb2f08aa51',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '86',\n",
       "   'date': 'Thu, 29 Jun 2023 22:45:15 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d7b78e9-51cf-44bc-8022-6f36456d5e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbe0a7d9-b6ae-4140-9083-1d0eec4183c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:107408944800:pipeline/SimilarityPipeline',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:107408944800:pipeline/SimilarityPipeline/execution/gu3sl7rh0o0d',\n",
       " 'PipelineExecutionDisplayName': 'execution-1688078716039',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2023, 6, 29, 22, 45, 15, 923000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 6, 29, 22, 45, 15, 923000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:107408944800:user-profile/d-i0sjo3grk8wo/default-1686222155051',\n",
       "  'UserProfileName': 'default-1686222155051',\n",
       "  'DomainId': 'd-i0sjo3grk8wo'},\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:107408944800:user-profile/d-i0sjo3grk8wo/default-1686222155051',\n",
       "  'UserProfileName': 'default-1686222155051',\n",
       "  'DomainId': 'd-i0sjo3grk8wo'},\n",
       " 'ResponseMetadata': {'RequestId': '1d66b3c0-59c9-4337-aea2-cec89e8e53be',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1d66b3c0-59c9-4337-aea2-cec89e8e53be',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '759',\n",
       "   'date': 'Thu, 29 Jun 2023 22:45:16 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0c16dd6-940e-47dd-ab20-7a535b935a60",
   "metadata": {},
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a2dfc2e-9cbb-4e06-9621-ee05ddbd583c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile code/evaluation.py\n",
    "# import json\n",
    "# import pathlib\n",
    "# import pickle\n",
    "# import tarfile\n",
    "\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import xgboost\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     model_path = f\"/opt/ml/processing/model/model.tar.gz\"\n",
    "#     with tarfile.open(model_path) as tar:\n",
    "#         tar.extractall(path=\".\")\n",
    "\n",
    "#     model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "\n",
    "#     test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "#     df = pd.read_csv(test_path, header=None)\n",
    "\n",
    "#     y_test = df.iloc[:, 0].to_numpy()\n",
    "#     df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "#     X_test = xgboost.DMatrix(df.values)\n",
    "\n",
    "#     predictions = model.predict(X_test)\n",
    "\n",
    "#     mse = mean_squared_error(y_test, predictions)\n",
    "#     std = np.std(y_test - predictions)\n",
    "#     report_dict = {\n",
    "#         \"regression_metrics\": {\n",
    "#             \"mse\": {\"value\": mse, \"standard_deviation\": std},\n",
    "#         },\n",
    "#     }\n",
    "\n",
    "#     output_dir = \"/opt/ml/processing/evaluation\"\n",
    "#     pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "#     with open(evaluation_path, \"w\") as f:\n",
    "#         f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67165566-00b9-4bb0-8ae8-4953d9e413c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "\n",
    "# script_eval = ScriptProcessor(\n",
    "#     image_uri=image_uri,\n",
    "#     command=[\"python3\"],\n",
    "#     instance_type=\"ml.m5.xlarge\",\n",
    "#     instance_count=1,\n",
    "#     base_job_name=\"script-abalone-eval\",\n",
    "#     role=role,\n",
    "#     sagemaker_session=pipeline_session,\n",
    "# )\n",
    "\n",
    "# eval_args = script_eval.run(\n",
    "#     inputs=[\n",
    "#         ProcessingInput(\n",
    "#             source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "#             destination=\"/opt/ml/processing/model\",\n",
    "#         ),\n",
    "#         ProcessingInput(\n",
    "#             source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "#             destination=\"/opt/ml/processing/test\",\n",
    "#         ),\n",
    "#     ],\n",
    "#     outputs=[\n",
    "#         ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "#     ],\n",
    "#     code=\"code/evaluation.py\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74817857-dd5a-4333-b616-f1bf0746f6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "# evaluation_report = PropertyFile(\n",
    "#     name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    "# )\n",
    "# step_eval = ProcessingStep(\n",
    "#     name=\"AbaloneEval\",\n",
    "#     step_args=eval_args,\n",
    "#     property_files=[evaluation_report],\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "683e401b-4f11-4997-abf4-35b329841809",
   "metadata": {},
   "source": [
    "create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "939d151f-d55c-47dc-83c0-9da0199c1344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.model import Model\n",
    "\n",
    "# model = Model(\n",
    "#     image_uri=image_uri,\n",
    "#     model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "#     sagemaker_session=pipeline_session,\n",
    "#     role=role,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3c3d5b6-f749-420a-bf70-0e11e962adc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.inputs import CreateModelInput\n",
    "# from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "# step_create_model = ModelStep(\n",
    "#     name=\"AbaloneCreateModel\",\n",
    "#     step_args=model.create(instance_type=\"ml.m4.large\", accelerator_type=\"ml.eia1.medium\"),\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adae92a5-4760-4c4a-9fcd-f35ddec3a1f5",
   "metadata": {},
   "source": [
    "transformation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df6fd00e-65e7-425d-9364-69f80063372c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.transformer import Transformer\n",
    "\n",
    "\n",
    "# transformer = Transformer(\n",
    "#     model_name=step_create_model.properties.ModelName,\n",
    "#     instance_type=\"ml.m5.xlarge\",\n",
    "#     instance_count=1,\n",
    "#     output_path=f\"s3://{default_bucket}/AbaloneTransform\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "425f2cbf-bc3e-4478-b4f2-b60e9a572d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.inputs import TransformInput\n",
    "# from sagemaker.workflow.steps import TransformStep\n",
    "\n",
    "\n",
    "# step_transform = TransformStep(\n",
    "#     name=\"AbaloneTransform\", transformer=transformer, inputs=TransformInput(data=batch_data)\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f77f0b0f-a12e-4d93-922d-6ed3c577280f",
   "metadata": {},
   "source": [
    "Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28a9274e-98a6-46bb-8af8-4aabecd3a610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = Model(\n",
    "#     image_uri=image_uri,\n",
    "#     model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "#     sagemaker_session=pipeline_session,\n",
    "#     role=role,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66a4b6f3-3c78-4cfb-abc2-b8ae9ac95d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "\n",
    "# model_metrics = ModelMetrics(\n",
    "#     model_statistics=MetricsSource(\n",
    "#         s3_uri=\"{}/evaluation.json\".format(\n",
    "#             step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "#         ),\n",
    "#         content_type=\"application/json\",\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# register_args = model.register(\n",
    "#     content_types=[\"text/csv\"],\n",
    "#     response_types=[\"text/csv\"],\n",
    "#     inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "#     transform_instances=[\"ml.m5.xlarge\"],\n",
    "#     model_package_group_name=model_package_group_name,\n",
    "#     approval_status=model_approval_status,\n",
    "#     model_metrics=model_metrics,\n",
    "# )\n",
    "# step_register = ModelStep(name=\"AbaloneRegisterModel\", step_args=register_args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ad2e24c-1381-4de4-9b40-47b6b18219ac",
   "metadata": {},
   "source": [
    "Define a Fail Step to Terminate the Pipeline Execution and Mark it as Failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0449f75f-a4da-41c9-9084-9fec9c1fc78a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.fail_step import FailStep\n",
    "# from sagemaker.workflow.functions import Join\n",
    "\n",
    "# step_fail = FailStep(\n",
    "#     name=\"AbaloneMSEFail\",\n",
    "#     error_message=Join(on=\" \", values=[\"Execution failed due to MSE >\", mse_threshold]),\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b0b2d0e-a347-4ec7-8165-4a033cc5850a",
   "metadata": {},
   "source": [
    "Condition Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66a1dd76-da54-43d7-9c84-863f6931e12a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "# from sagemaker.workflow.condition_step import ConditionStep\n",
    "# from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "\n",
    "# cond_lte = ConditionLessThanOrEqualTo(\n",
    "#     left=JsonGet(\n",
    "#         step_name=step_eval.name,\n",
    "#         property_file=evaluation_report,\n",
    "#         json_path=\"regression_metrics.mse.value\",\n",
    "#     ),\n",
    "#     right=mse_threshold,\n",
    "# )\n",
    "\n",
    "# step_cond = ConditionStep(\n",
    "#     name=\"AbaloneMSECond\",\n",
    "#     conditions=[cond_lte],\n",
    "#     if_steps=[step_register, step_create_model, step_transform],\n",
    "#     else_steps=[step_fail],\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9ab0d7e-8ab9-4065-8bd3-80c0a17c4cba",
   "metadata": {},
   "source": [
    "define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a195dbe6-c13a-42d3-9743-1a5edb108715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# pipeline_name = f\"AbalonePipeline\"\n",
    "# pipeline = Pipeline(\n",
    "#     name=pipeline_name,\n",
    "#     parameters=[\n",
    "#         processing_instance_count,\n",
    "#         instance_type,\n",
    "#         model_approval_status,\n",
    "#         input_data,\n",
    "#         batch_data,\n",
    "#         mse_threshold,\n",
    "#     ],\n",
    "#     steps=[step_process, step_train, step_eval, step_cond],\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7bcc0bb-1c6f-45aa-8cdd-1c70dac5e9de",
   "metadata": {},
   "source": [
    "Submit and execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dffaeed6-afcf-431e-b3bc-1209377fffa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pipeline.upsert(role_arn=role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6bba53c-cd35-4de5-8417-f018ccc1ebac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93a7fb55-cc18-4d97-a357-6914a6a7c3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d712eaa-5bdf-4390-b84f-4744b773735c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2205cf9e-74c0-42ce-b11d-ffa953199e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
